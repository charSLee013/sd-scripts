# SDXL LoRA 卓越模型训练配置 v3.0 - 最优版本
# 基于 NovelAI V3 论文和 sd-scripts 代码分析的最佳实践

# ================================
# 基础模型路径配置
# ================================
pretrained_model_name_or_path = "/root/checkpoints/sd_xl_base_1.0.safetensors"
vae = "/root/checkpoints/sdxl_vae.safetensors"

# ================================
# 数据集配置
# ================================
train_data_dir = "/root/data/cluster_4_restructured_v2"
output_dir = "./models/sdxl_lora_v3_optimal"
logging_dir = "./logs/sdxl_lora_v3_optimal"

# ================================
# 分辨率和批处理配置
# ================================
# SDXL 标准分辨率
resolution = 1024
# 快速验证批处理大小
train_batch_size = 1
# 梯度累积以提升有效批处理大小
gradient_accumulation_steps = 4

# ================================
# 训练轮次和保存配置
# ================================
max_train_epochs = 10
save_every_n_epochs = 2
save_model_as = "safetensors"

# ================================
# 学习率配置 (基于NovelAI V3论文)
# ================================
learning_rate = 1e-4
# U-Net 学习率（主要网络）
unet_lr = 1e-4
# 文本编码器学习率（较低以保持稳定性）
text_encoder_lr = 5e-5
# Cosine with Restarts 调度器（NovelAI V3 推荐）
lr_scheduler = "cosine_with_restarts"
lr_scheduler_num_cycles = 3
lr_warmup_steps = 100

# ================================
# LoRA 网络配置 (快速验证)
# ================================
network_module = "networks.lora"
network_dim = 64
network_alpha = 32
# 训练所有 LoRA 层
network_train_unet_only = false
network_train_text_encoder_only = false

# ================================
# 优化器配置
# ================================
optimizer_type = "AdamW8bit"
optimizer_args = ["weight_decay=0.1", "betas=0.9,0.99"]

# ================================
# Token 长度配置 (SDXL最佳实践)
# ================================
max_token_length = 225

# ================================
# NovelAI V3 关键技术参数
# ================================
# V-Parameterization (论文强调的关键技术)
v_parameterization = true
# Min SNR Gamma for Zero Terminal SNR approximation
min_snr_gamma = 5
# Noise offset for better dynamic range
noise_offset = 0.05
# 多尺度噪声改善细节
multires_noise_iterations = 6
multires_noise_discount = 0.3

# ================================
# 性能优化配置
# ================================
# 混合精度训练
mixed_precision = "fp16"
# 梯度检查点节省内存
gradient_checkpointing = true
# 禁用xformers（用户要求）
# xformers = false
# 启用深度学习优化（用户要求）
# deepspeed = true  # 注：需要在accelerate config中配置
# 缓存文本编码器输出
cache_text_encoder_outputs = true
cache_text_encoder_outputs_to_disk = true
# SDXL VAE FP32运行以避免NaN
vae_batch_size = 1
no_half_vae = true

# ================================
# 数据加载优化
# ================================
persistent_data_loader_workers = true
max_data_loader_n_workers = 2

# ================================
# 采样配置
# ================================
sample_every_n_epochs = 2
sample_prompts = "./prompts.txt"
sample_sampler = "euler_a"
sample_steps = 20

# ================================
# 高级训练技术
# ================================
# 随机裁剪增强
random_crop = false
# 颜色增强
color_aug = false
# IP噪声Gamma（改善训练稳定性）
ip_noise_gamma = 0.1
# Scale v-prediction loss
scale_v_pred_loss_like_noise_pred = true

# ================================
# 日志和监控
# ================================
log_with = "tensorboard"
log_prefix = "sdxl_lora_v3_optimal"

# ================================
# 高级内存优化
# ================================
# 启用CPU卸载
cpu_offload_checkpointing = true
# 低内存VAE
lowvram = false

# ================================
# 实验性功能 (基于最新研究)
# ================================
# SDXL专用：改善文本-图像对齐
# 注意：这些参数可能需要根据具体硬件调整
full_fp16 = false
fp8_base = false  # 如果显存充足可以开启

# ================================
# 正则化配置
# ================================
# 权重衰减通过optimizer_args配置
# Dropout（如果需要）
# network_dropout = 0.0

# ================================
# Bucket配置 (多分辨率训练)
# ================================
enable_bucket = true
min_bucket_reso = 256
max_bucket_reso = 1536
bucket_reso_steps = 64
bucket_no_upscale = false 