# SDXL LoRA 卓越模型训练配置 v3.0 - 最优版本
# 基于 NovelAI V3 论文和 sd-scripts 代码分析的最佳实践

# ================================
# 基础模型路径配置
# ================================
pretrained_model_name_or_path = "/root/checkpoints/sd_xl_base_1.0.safetensors"
vae = "/root/checkpoints/sdxl_vae.safetensors"

# ================================
# 数据集配置
# ================================
train_data_dir = "/root/data/cluster_4_restructured_v3"
reg_data_dir = ""  # 如果不使用正则化数据集可以留空
output_dir = "./models/sdxl_lora_v3_optimal"
logging_dir = "./logs/sdxl_lora_v3_optimal"

# ================================
# 分辨率和批处理配置
# ================================
# SDXL 标准分辨率
resolution = "1024,1024"
# 快速验证批处理大小
train_batch_size = 2
# 梯度累积以提升有效批处理大小
gradient_accumulation_steps = 4

# ================================
# 训练轮次和保存配置
# ================================
# 基于步数训练，而非基于epoch
max_train_steps = 10000     # 总训练步数为10000
save_every_n_steps = 500   # 每500步保存一次模型
save_model_as = "safetensors"

# ================================
# 学习率配置 (基于NovelAI V3论文)
# ================================
learning_rate = 1e-4
# U-Net 学习率（主要网络）
unet_lr = 1e-4
# 文本编码器学习率（较低以保持稳定性）
text_encoder_lr = 5e-5
# Cosine with Restarts 调度器（NovelAI V3 推荐）
lr_scheduler = "cosine_with_restarts"
lr_scheduler_num_cycles = 3
lr_warmup_steps = 100

# ================================
# LoRA 网络配置 (快速验证)
# ================================
network_module = "networks.lora"
network_dim = 64
network_alpha = 32
# 训练所有 LoRA 层
network_train_unet_only = false
network_train_text_encoder_only = false

# ================================
# 优化器配置
# ================================
# 由于bitsandbytes安装失败，使用标准AdamW优化器
optimizer_type = "AdamW"
optimizer_args = ["weight_decay=0.1", "betas=0.9,0.99"]

# ================================
# Token 长度配置 (SDXL最佳实践)
# ================================
max_token_length = 225

# ================================
# NovelAI V3 关键技术参数
# ================================
# V-Parameterization (论文强调的关键技术)
v_parameterization = true
# Min SNR Gamma for Zero Terminal SNR approximation
min_snr_gamma = 5
# Noise offset for better dynamic range
noise_offset = 0.05
# 多尺度噪声改善细节
multires_noise_iterations = 6
multires_noise_discount = 0.3

# ================================
# 性能优化配置
# ================================
# 混合精度训练
mixed_precision = "bf16"
# 梯度检查点节省内存
gradient_checkpointing = true
# 启用xformers以减少内存使用
xformers = false
# 已移除DeepSpeed支持（不再使用accelerate启动）

# 缓存文本编码器输出 - 已禁用（与LoRA Text Encoder训练冲突）
cache_text_encoder_outputs = false
cache_text_encoder_outputs_to_disk = false
# SDXL VAE FP32运行以避免NaN
vae_batch_size = 16
no_half_vae = true

# ================================
# 数据加载优化
# ================================
persistent_data_loader_workers = true
max_data_loader_n_workers = 2

# ================================
# 采样配置
# ================================
sample_every_n_steps = 500   # 每500步采样一次
sample_prompts = "./prompts.txt"
sample_sampler = "euler_a"
sample_steps = 20

# ================================
# 高级训练技术
# ================================
# 随机裁剪增强
random_crop = false
# 颜色增强
color_aug = false
# IP噪声Gamma（改善训练稳定性）
ip_noise_gamma = 0.1
# Scale v-prediction loss
scale_v_pred_loss_like_noise_pred = true

# ================================
# 提示词处理配置
# ================================
# 启用标签随机打乱，提升泛化能力
shuffle_caption = true
# 启用通配符和多行提示词
enable_wildcard = true
# 使用.txt作为标签文件扩展名
caption_extension = ".txt"

# ================================
# 日志和监控
# ================================
log_with = "tensorboard"
log_prefix = "sdxl_lora_v3_optimal"

# ================================
# 高级内存优化
# ================================
# 禁用CPU卸载，直接使用GPU显存
cpu_offload_checkpointing = false
# 禁用低内存模式，优先使用显存
lowvram = false
highvram = true
lowram = true
# 加载模型和VAE到GPU显存，提高训练效率
use_cpu_only = false  # 确保使用GPU
vae_in_cpu = false    # VAE直接加载到GPU显存
train_on_main_process_only = false  # 充分利用所有可用资源

# ================================
# 实验性功能 (基于最新研究)
# ================================
# SDXL专用：改善文本-图像对齐
# 注意：这些参数可能需要根据具体硬件调整
full_fp16 = false
fp8_base = true  # 如果显存不足可以开启

# ================================
# 正则化配置
# ================================
# 权重衰减通过optimizer_args配置
# Dropout（如果需要）
# network_dropout = 0.0

# ================================
# Bucket配置 (多分辨率训练)
# ================================
enable_bucket = true
min_bucket_reso = 512
max_bucket_reso = 4096
bucket_reso_steps = 64
bucket_no_upscale = false 